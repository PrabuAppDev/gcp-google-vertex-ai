{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bdb0d1-f30c-4726-9259-65c2ca1185df",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User uploads PDF manual] --> B[Chunk + Embed PDF content]\n",
    "    B --> C[Upload embeddings to Vertex AI Vector Index]\n",
    "    C --> D[Create public Index Endpoint]\n",
    "\n",
    "    subgraph Vertex AI\n",
    "        C\n",
    "        D\n",
    "    end\n",
    "\n",
    "    E[User asks a question about the Acura MDX] --> F[Query Vertex AI Matching Engine]\n",
    "    F --> G[Retrieve relevant chunks]\n",
    "\n",
    "    G --> H[Gemini LLM generates response]\n",
    "    H --> I[Show Answer to User]\n",
    "\n",
    "    %% Crew AI Integration\n",
    "    subgraph Crew AI Agents\n",
    "        J[Weather Agent - Winter]\n",
    "        K[Manual Review Agent]\n",
    "        L[Recommendation Agent]\n",
    "    end\n",
    "\n",
    "    J --> M[Inject seasonal context]\n",
    "    G --> K\n",
    "    K --> L\n",
    "    L --> H\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868ab12-08bf-4535-a747-15f62018ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-storage\n",
    "# üß± Cell 1: Setup environment and initialize Vertex AI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Set ADC to correct service account\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"GCP_KEY_PATH\")\n",
    "\n",
    "# Init Vertex AI under the correct project\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "vertexai.init(project=project_id, location=os.getenv(\"VERTEX_REGION\"))\n",
    "aiplatform.init(project=project_id, location=os.getenv(\"VERTEX_REGION\"))\n",
    "\n",
    "print(f\"‚úÖ Vertex AI initialized in project: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15a60d-f8fd-4955-b265-812a0d9df250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 2 (refactored): Recreate correct GCS bucket and upload Acura MDX PDF\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import storage\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv()\n",
    "\n",
    "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "GCS_BUCKET_NAME = os.getenv(\"GCS_BUCKET_NAME\")\n",
    "GCS_BUCKET_REGION = os.getenv(\"GCS_BUCKET_REGION\")\n",
    "PDF_LOCAL_PATH = os.getenv(\"PDF_LOCAL_PATH\")\n",
    "GCS_DEST_PATH = os.getenv(\"GCS_DEST_PATH\")\n",
    "\n",
    "\n",
    "# ‚úÖ Create GCS bucket (no deprecated warning)\n",
    "def create_bucket(bucket_name, location):\n",
    "    try:\n",
    "        bucket = client.lookup_bucket(bucket_name)\n",
    "        if bucket:\n",
    "            print(f\"‚úÖ Bucket '{bucket_name}' already exists.\")\n",
    "        else:\n",
    "            print(f\"üì¶ Creating bucket: {bucket_name} in region: {location} ...\")\n",
    "            bucket = client.bucket(bucket_name)\n",
    "            new_bucket = client.create_bucket(bucket, location=location)\n",
    "            print(f\"‚úÖ Bucket '{bucket_name}' created in {location}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating bucket: {e}\")\n",
    "\n",
    "# Upload PDF to GCS\n",
    "def upload_file_to_gcs(bucket_name, source_path, destination_blob):\n",
    "    # print(f\"üì§ Uploading '{source_path}' to 'gs://{bucket_name}/{destination_blob}' ...\")\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob)\n",
    "    blob.upload_from_filename(source_path)\n",
    "    print(f\"‚úÖ Upload complete.\")\n",
    "\n",
    "# Execute\n",
    "create_bucket(GCS_BUCKET_NAME, GCS_BUCKET_REGION)\n",
    "upload_file_to_gcs(GCS_BUCKET_NAME, PDF_LOCAL_PATH, GCS_DEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4893a0f-88ed-42a1-91af-1e3fe5a331a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 3 (rewritten): Layout-aware chunking using PyMuPDF for better accuracy\n",
    "\n",
    "# !pip install --upgrade pymupdf\n",
    "import fitz  # This is PyMuPDF (not the wrong 'fitz' package)\n",
    "\n",
    "def extract_and_chunk_pdf_layout(pdf_path, max_chars=2000, overlap_chars=200):\n",
    "    print(f\"üì• Loading PDF: {pdf_path}\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "    print(f\"üìÑ PDF has {len(doc)} pages.\")\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    metadata = []\n",
    "\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        text = page.get_text(\"text\")\n",
    "        if not text or len(text.strip()) < 100:\n",
    "            continue  # skip blank or low-content pages\n",
    "\n",
    "        lines = text.strip().splitlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if len(current_chunk) + len(line) + 1 > max_chars:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                metadata.append({\"page\": page_num})\n",
    "                current_chunk = current_chunk[-overlap_chars:] + \"\\n\" + line\n",
    "            else:\n",
    "                current_chunk += \"\\n\" + line\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "        metadata.append({\"page\": len(doc)})\n",
    "\n",
    "    print(f\"‚úÖ Chunking complete: {len(chunks)} layout-aware chunks created.\")\n",
    "    return chunks, metadata\n",
    "\n",
    "# Use the local path from .env\n",
    "pdf_path = os.getenv(\"PDF_LOCAL_PATH\")\n",
    "text_chunks, chunk_metadata = extract_and_chunk_pdf_layout(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50ac77-41db-48c5-a24a-69ce1a57f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 4: Embed text chunks using sentence-transformers (local) with incremental logging\n",
    "\n",
    "# !pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "\n",
    "# Load model (384-dim, small + fast)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_locally(chunks, log_every=25):\n",
    "    print(f\"üî¢ Embedding {len(chunks)} chunks locally with 'all-MiniLM-L6-v2'...\")\n",
    "\n",
    "    records = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        embedding = model.encode(chunk)\n",
    "        records.append({\n",
    "            \"id\": f\"chunk-{str(uuid.uuid4())}\",\n",
    "            \"content\": chunk,\n",
    "            \"embedding\": embedding.tolist()\n",
    "        })\n",
    "\n",
    "        if (i + 1) % log_every == 0 or (i + 1) == len(chunks):\n",
    "            print(f\"‚úÖ Embedded {i + 1}/{len(chunks)} chunks...\")\n",
    "\n",
    "    print(\"‚úÖ All embeddings complete.\")\n",
    "    return records\n",
    "\n",
    "# Run it\n",
    "embedding_records = embed_locally(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bed59-93ad-46e1-b1ad-cf557a0a06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üß± Reload .env to ensure the updated GCS bucket name is used\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# load_dotenv(find_dotenv(), override=True)  # This loads the .env file\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Confirm GCS bucket name\n",
    "# print(f\"GCS Bucket Name: {os.getenv('GCS_BUCKET_NAME')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7585934-64b7-4128-a40c-8a23d2d18e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 5: Save embedding records to JSON and upload to GCS\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)  # This loads the .env file\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Save as JSON (update to .json extension)\n",
    "json_path = \"vector_data.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for record in embedding_records:\n",
    "        json.dump(record, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved {len(embedding_records)} records to {json_path}\")\n",
    "\n",
    "# Upload to GCS (new file extension .json)\n",
    "json_gcs_path = \"vector_data/vector_data.json\"\n",
    "upload_file_to_gcs(GCS_BUCKET_NAME, json_path, json_gcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7b0dc-0c30-4097-9016-1ae784a1b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üß™ Validate local vector_data.jsonl format and dimensions\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(\"vector_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         try:\n",
    "#             obj = json.loads(line)\n",
    "#             assert isinstance(obj[\"id\"], str), \"Missing or invalid 'id'\"\n",
    "#             assert isinstance(obj[\"content\"], str), \"Missing or invalid 'content'\"\n",
    "#             assert isinstance(obj[\"embedding\"], list), \"Missing or invalid 'embedding'\"\n",
    "#             assert len(obj[\"embedding\"]) == 384, f\"Invalid dimension: {len(obj['embedding'])}\"\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ùå Error on line {i + 1}: {e}\")\n",
    "#             break\n",
    "#     else:\n",
    "#         print(\"‚úÖ All lines are valid and have correct 384-dim embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dbd7b-fa24-4664-8049-3eb0ba63c048",
   "metadata": {},
   "source": [
    "**` Created Vector Index in GCP UI/Console `**\n",
    "\n",
    "![image](vector-ai-index-creation.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869bca3b-714b-4f32-844f-a8bed7617c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell: List all available index endpoints in your project/region\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Make sure init was done earlier\n",
    "index_endpoints = aiplatform.MatchingEngineIndexEndpoint.list()\n",
    "\n",
    "print(f\"üîç Found {len(index_endpoints)} endpoint(s):\\n\")\n",
    "for ep in index_endpoints:\n",
    "    print(f\"üìå Name       : {ep.resource_name}\")\n",
    "    print(f\"    Display   : {ep.display_name}\")\n",
    "    print(f\"    Created   : {ep.create_time}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78db6b-422f-49c9-8faf-8aefd461eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 6: Create MatchingEngineIndexEndpoint with public access\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "\n",
    "endpoint_display_name = \"acura-mdx-index-endpoint\"\n",
    "\n",
    "# Create the endpoint (do NOT reuse the returned object)\n",
    "created_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=endpoint_display_name,\n",
    "    public_endpoint_enabled=True,\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "# Store the name\n",
    "new_endpoint_resource_name = created_endpoint.resource_name\n",
    "print(f\"‚úÖ Created endpoint: {new_endpoint_resource_name}\")\n",
    "\n",
    "# Sleep to avoid premature NotFound errors\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cab186-7876-4fe3-9fda-9cb80e3b4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 7: Reload endpoint and deploy index\n",
    "# CAUTION LONG RUNNING CELL\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Load index resource name from .env\n",
    "index_resource_name = os.getenv(\"INDEX_RESOURCE_NAME\")\n",
    "\n",
    "# Reload index and newly created endpoint\n",
    "index = aiplatform.MatchingEngineIndex(index_resource_name)\n",
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint(new_endpoint_resource_name)\n",
    "\n",
    "# Generate a valid deployed index ID\n",
    "deployed_index_id = f\"acura_mdx_{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# Deploy the index\n",
    "index_endpoint.deploy_index(\n",
    "    index=index,\n",
    "    deployed_index_id=deployed_index_id,\n",
    "    display_name=\"acura-mdx-deployment\"\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Index deployed with ID: {deployed_index_id}\")\n",
    "\n",
    "# Wait briefly to ensure deployment is fully initialized\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30a3e2-7d91-425f-84fa-aa241378d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Reload updated .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Load correct endpoint name from .env\n",
    "index_endpoint_name = os.getenv(\"INDEX_ENDPOINT_NAME\")\n",
    "print(\"‚úÖ Using updated endpoint:\", index_endpoint_name)\n",
    "# Load from env\n",
    "deployed_index_id = os.getenv(\"DEPLOYED_INDEX_ID\")\n",
    "print(f\"üì¶ Using deployed index ID: {deployed_index_id}\")\n",
    "\n",
    "location=os.getenv(\"VERTEX_REGION\")\n",
    "print(f\"üì¶ Using location: {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4510b48-f45a-4f47-b243-62ae97c525e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Cell 8: Embed and query using text-embedding-005 (768-dim vectors)\n",
    "\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "import os\n",
    "\n",
    "# Load the deployed index and endpoint\n",
    "index = aiplatform.MatchingEngineIndex(os.getenv(\"INDEX_RESOURCE_NAME\"))\n",
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint(os.getenv(\"INDEX_ENDPOINT_NAME\"))\n",
    "\n",
    "# Embed using the correct model for current project + 768-dim\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "test_query = \"How do I enable snow mode in the Acura MDX?\"\n",
    "query_embedding = embedding_model.get_embeddings([test_query])[0].values\n",
    "\n",
    "# Query\n",
    "neighbors = index_endpoint.find_neighbors(\n",
    "    deployed_index_id=os.getenv(\"DEPLOYED_INDEX_ID\"),\n",
    "    queries=[query_embedding],\n",
    "    num_neighbors=5,\n",
    "    return_full_datapoint=True,\n",
    ")\n",
    "\n",
    "# Print top results\n",
    "for i, match in enumerate(neighbors[0], 1):\n",
    "    print(f\"{i}. Score: {match.distance:.4f} | ID: {match.datapoint.datapoint_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
